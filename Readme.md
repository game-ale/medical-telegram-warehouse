# Medical Telegram Warehouse ğŸ¥ğŸ’Š

**An end-to-end data engineering pipeline for extracting, transforming, and analyzing medical business data from Ethiopian Telegram channels.**

---

## ğŸ“– Overview

The **Medical Telegram Warehouse** is a data product designed to collect, store, and analyze real-time data from public Telegram channels focusing on the Ethiopian medical and pharmaceutical market.

The system answers key business questions such as:
- What are the trending medical products?
- How does pricing vary across channels?
- Which channels have the highest engagement?
- What are the visual trends in product marketing?

This project follows a modern **ELT (Extract, Load, Transform)** architecture:
1.  **Extract**: Scrape raw messages and images from Telegram using `Telethon`.
2.  **Load**: Store raw data in a Data Lake (JSON) and then load into `PostgreSQL`.
3.  **Transform**: Clean and model data into a Star Schema using `dbt`.
4.  **Enrich**: unique object detection on product images using `YOLOv8`.
5.  **Serve**: Expose insights via a `FastAPI` analytical interface.
6.  **Orchestrate**: Manage the entire workflow with `Dagster`.

---

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    TG[Telegram API] --> |Scraper| DL[Data Lake (JSON + Images)]
    DL --> |Loader| DB[(PostgreSQL DW)]
    DB --> |dbt| Marts[Data Marts (Star Schema)]
    DL --> |YOLOv8| ML[Object Detection]
    ML --> |Enrichment| DB
    Marts --> |FastAPI| API[Analytical API]
    API --> User
```

## ğŸš€ Getting Started

### Prerequisites
- **Python 3.10+**
- **Docker & Docker Compose**
- **PostgreSQL** (if running locally without Docker)
- **Telegram API Credentials** (Get them from [my.telegram.org](https://my.telegram.org))

### 1. Installation

Clone the repository:
```bash
git clone https://github.com/game-ale/medical-telegram-warehouse.git
cd medical-telegram-warehouse
```

Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

Install dependencies:
```bash
pip install -r requirements.txt
```

### 2. Configuration

Create a `.env` file from the example:
```bash
cp .env.example .env
```

**Critical Step**: Open `.env` and fill in your Telegram credentials:
```ini
TG_API_ID=12345678
TG_API_HASH=your_secret_hash_here
TG_PHONE=+251911223344
```

### 3. Running the Scraper (Task 1)

To start collecting data:
```bash
python src/scraper.py
```
*Note: On the first run, you will be prompted to enter a login code sent to your Telegram account.*

This will populate the **Data Lake**:
- Messages: `data/raw/telegram_messages/YYYY-MM-DD/channel_name.json`
- Images: `data/raw/images/channel_name/message_id.jpg`

---

## ğŸ“‚ Project Structure

```
medical-telegram-warehouse/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/               # The Data Lake
â”‚       â”œâ”€â”€ images/        # Downloaded images organized by channel
â”‚       â””â”€â”€ telegram_messages/ # Daily JSON dumps of channel messages
â”œâ”€â”€ medical_warehouse/     # dbt project (Task 2)
â”‚   â”œâ”€â”€ models/            # Staging and Marts models
â”‚   â””â”€â”€ seeds/             # Static reference data
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py         # Telegram data extraction script
â”‚   â””â”€â”€ ...
â”œâ”€â”€ api/                   # FastAPI application (Task 4)
â”œâ”€â”€ scripts/               # Helper scripts
â”œâ”€â”€ tests/                 # Unit and data tests
â”œâ”€â”€ docker-compose.yml     # Service orchestration
â””â”€â”€ requirements.txt       # Python dependencies
```

## ğŸ“Š Current Status

- **[x] Task 1: Data Scraping & Collection**
    - Scraper implemented and validated.
    - Data Lake structure established.
    - Successfully extracting text, metadata, and images.
- **[ ] Task 2: Data Modeling (dbt)** (In Progress)
    - Loading JSON to Postgres.
    - Designing Star Schema (`dim_channels`, `fct_messages`).
- **[ ] Task 3: Object Detection (YOLO)**
- **[ ] Task 4: API Development**
- **[ ] Task 5: Orchestration (Dagster)**

---

## ğŸ¤ Contribution
This project is part of the 10 Academy Weekly Challenge suitable for Portfolio Construction.
